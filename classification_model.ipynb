{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd3f0ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OrdinalEncoder, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import dagshub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5256145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (404800, 27)\n",
      "\n",
      "Class distribution:\n",
      "emi_eligibility\n",
      "Not_Eligible    312868\n",
      "Eligible         74444\n",
      "High_Risk        17488\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"clean_emi_data.csv\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df['emi_eligibility'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e79a24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop(['emi_eligibility', 'max_monthly_emi'], axis=1)\n",
    "y = df['emi_eligibility']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c144c",
   "metadata": {},
   "source": [
    "Hndling Class Inbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44fa0481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTENC for class balancing...\n",
      "\n",
      "Balanced class distribution:\n",
      "emi_eligibility\n",
      "Not_Eligible    312868\n",
      "Eligible        312868\n",
      "High_Risk       312868\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Encoded classes: ['Eligible' 'High_Risk' 'Not_Eligible']\n",
      "Encoded values: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical columns for SMOTENC\n",
    "categorical_cols = ['gender', 'marital_status', 'education', 'employment_type',\n",
    "                    'company_type', 'house_type', 'existing_loans', 'emi_scenario']\n",
    "categorical_indices = [X.columns.get_loc(col) for col in categorical_cols]\n",
    "\n",
    "# Apply SMOTENC to balance classes\n",
    "print(\"\\nApplying SMOTENC for class balancing...\")\n",
    "smote = SMOTENC(categorical_features=categorical_indices, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "print(\"\\nBalanced class distribution:\")\n",
    "print(pd.Series(y_resampled).value_counts())\n",
    "\n",
    "# Label encode target\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_resampled)\n",
    "\n",
    "print(\"\\nEncoded classes:\", le.classes_)\n",
    "print(\"Encoded values:\", np.unique(y_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa99f0ea",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e946c160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: (750883, 25), Test: (187721, 25)\n",
      "Train class dist: [250295 250294 250294]\n",
      "Test class dist: [62573 62574 62574]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain: {X_train.shape}, Test: {X_test.shape}\")\n",
    "print(f\"Train class dist: {np.bincount(y_train)}\")\n",
    "print(f\"Test class dist: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565788fa",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "541b0caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        # Create new features\n",
    "        X['debt_to_income'] = X['current_emi_amount'] / (X['monthly_salary'] + 1e-6)\n",
    "        X['total_monthly_expenses'] = (\n",
    "            X['monthly_rent'] + X['school_fees'] + X['college_fees'] +\n",
    "            X['travel_expenses'] + X['groceries_utilities'] + \n",
    "            X['other_monthly_expenses'] + X['current_emi_amount']\n",
    "        )\n",
    "        X['expense_to_income'] = X['total_monthly_expenses'] / (X['monthly_salary'] + 1e-6)\n",
    "        X['available_for_new_emi'] = X['monthly_salary'] - X['total_monthly_expenses']\n",
    "        X['employment_stability_score'] = X['years_of_employment'] / (X['requested_tenure'] + 1e-6)\n",
    "        X['credit_risk_score'] = 1 - (X['credit_score'] / 850)\n",
    "        X['emergency_coverage_months'] = X['emergency_fund'] / (X['total_monthly_expenses'] + 1e-6)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92d242ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Low skew: 6 features\n",
      "Moderate skew: 9 features\n",
      "High skew: 9 features\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate skewness on TRAINING data only\n",
    "feature_engineer = FeatureEngineer()\n",
    "X_train_fe = feature_engineer.fit_transform(X_train)\n",
    "\n",
    "num_columns = X_train_fe.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "skewness = X_train_fe[num_columns].skew()\n",
    "\n",
    "low_skew = skewness[abs(skewness) <= 0.5].index.tolist()\n",
    "moderate_skew = skewness[(abs(skewness) > 0.5) & (abs(skewness) <= 1)].index.tolist()\n",
    "high_skew = skewness[abs(skewness) > 1].index.tolist()\n",
    "\n",
    "# Categorical columns\n",
    "nominal_columns = ['gender', 'marital_status', 'employment_type', 'company_type', 'house_type', 'emi_scenario']\n",
    "ordinal_columns = ['education']\n",
    "binary_columns = ['existing_loans']\n",
    "\n",
    "education_order = ['High School', 'Graduate', 'Professional', 'Post Graduate']\n",
    "\n",
    "print(f\"\\nLow skew: {len(low_skew)} features\")\n",
    "print(f\"Moderate skew: {len(moderate_skew)} features\")\n",
    "print(f\"High skew: {len(high_skew)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4828c6e6",
   "metadata": {},
   "source": [
    "Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0429a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_log_transform(X):\n",
    "    return np.log1p(np.clip(X, a_min=0, a_max=None))\n",
    "\n",
    "# Numeric pipelines\n",
    "numeric_low = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "numeric_mod = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('log', FunctionTransformer(safe_log_transform, feature_names_out='one-to-one')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "numeric_high = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('log', FunctionTransformer(safe_log_transform, feature_names_out='one-to-one')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical pipelines\n",
    "categorical_nominal = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "categorical_ordinal = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ord', OrdinalEncoder(categories=[education_order]))\n",
    "])\n",
    "\n",
    "categorical_binary = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ord', OrdinalEncoder(categories=[['No', 'Yes']], handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "# Column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('low_skew', numeric_low, low_skew),\n",
    "        ('mod_skew', numeric_mod, moderate_skew),\n",
    "        ('high_skew', numeric_high, high_skew),\n",
    "        ('nominal', categorical_nominal, nominal_columns),\n",
    "        ('ordinal', categorical_ordinal, ordinal_columns),\n",
    "        ('binary', categorical_binary, binary_columns)\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    verbose_feature_names_out=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf33c3e",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eec3e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selector = SelectFromModel(\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    threshold='median'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d3334e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ba01b84",
   "metadata": {},
   "source": [
    "MLFLow Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "341b465c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as SachinMosambe\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as SachinMosambe\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"SachinMosambe/AI-Intelligent-Financial-Risk-Assessment-Platform\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"SachinMosambe/AI-Intelligent-Financial-Risk-Assessment-Platform\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository SachinMosambe/AI-Intelligent-Financial-Risk-Assessment-Platform initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository SachinMosambe/AI-Intelligent-Financial-Risk-Assessment-Platform initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='SachinMosambe', repo_name='AI-Intelligent-Financial-Risk-Assessment-Platform', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bea61010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/efec4983388c4b26877b9ba378b2c8e3', creation_time=1761333047364, experiment_id='3', last_update_time=1761333047364, lifecycle_stage='active', name='Classification_Models', tags={}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"https://dagshub.com/SachinMosambe/AI-Intelligent-Financial-Risk-Assessment-Platform.mlflow\")\n",
    "mlflow.set_experiment(\"Classification_Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e746ff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"XGBoost Classifier\": XGBClassifier(n_estimators=200, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "cv_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303d0fc7",
   "metadata": {},
   "source": [
    "Cross-validation + metrics logging for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904d4a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Accuracy=0.8489, Precision=0.8567, Recall=0.8489, F1=0.8507\n",
      "üèÉ View run Logistic Regression_CV at: https://dagshub.com/SachinMosambe/AI-Intelligent-Financial-Risk-Assessment-Platform.mlflow/#/experiments/3/runs/877dc05c5ced48aab4e3a279ff2a3c56\n",
      "üß™ View experiment at: https://dagshub.com/SachinMosambe/AI-Intelligent-Financial-Risk-Assessment-Platform.mlflow/#/experiments/3\n",
      "Decision Tree: Accuracy=0.9057, Precision=0.9063, Recall=0.9060, F1=0.9060\n",
      "üèÉ View run Decision Tree_CV at: https://dagshub.com/SachinMosambe/AI-Intelligent-Financial-Risk-Assessment-Platform.mlflow/#/experiments/3/runs/3e58f9d17431422d8bb1c0b2f9f75331\n",
      "üß™ View experiment at: https://dagshub.com/SachinMosambe/AI-Intelligent-Financial-Risk-Assessment-Platform.mlflow/#/experiments/3\n",
      "K-Nearest Neighbors: Accuracy=0.8761, Precision=0.8929, Recall=0.8761, F1=0.8776\n",
      "üèÉ View run K-Nearest Neighbors_CV at: https://dagshub.com/SachinMosambe/AI-Intelligent-Financial-Risk-Assessment-Platform.mlflow/#/experiments/3/runs/a5283ba26a224eb8acadd96f5a2e8e03\n",
      "üß™ View experiment at: https://dagshub.com/SachinMosambe/AI-Intelligent-Financial-Risk-Assessment-Platform.mlflow/#/experiments/3\n",
      "Random Forest: Accuracy=0.9534, Precision=0.9548, Recall=0.9534, F1=0.9536\n",
      "üèÉ View run Random Forest_CV at: https://dagshub.com/SachinMosambe/AI-Intelligent-Financial-Risk-Assessment-Platform.mlflow/#/experiments/3/runs/f17417773eb945adb810fe3109e7616f\n",
      "üß™ View experiment at: https://dagshub.com/SachinMosambe/AI-Intelligent-Financial-Risk-Assessment-Platform.mlflow/#/experiments/3\n",
      "XGBoost Classifier: Accuracy=0.9460, Precision=0.9468, Recall=0.9460, F1=0.9461\n",
      "üèÉ View run XGBoost Classifier_CV at: https://dagshub.com/SachinMosambe/AI-Intelligent-Financial-Risk-Assessment-Platform.mlflow/#/experiments/3/runs/0e6ec67259e1434983835f82ad016b90\n",
      "üß™ View experiment at: https://dagshub.com/SachinMosambe/AI-Intelligent-Financial-Risk-Assessment-Platform.mlflow/#/experiments/3\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    with mlflow.start_run(run_name=f\"{name}_CV\"):\n",
    "        pipeline = Pipeline([\n",
    "            ('feature_engineering', FeatureEngineer()),\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('feature_selector', feature_selector),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "\n",
    "        # CV metrics\n",
    "        accuracy_scores  = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring=make_scorer(accuracy_score), n_jobs=-1)\n",
    "        precision_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring=make_scorer(precision_score, average='weighted'), n_jobs=-1)\n",
    "        recall_scores    = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring=make_scorer(recall_score, average='weighted'), n_jobs=-1)\n",
    "        f1_scores        = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring=make_scorer(f1_score, average='weighted'), n_jobs=-1)\n",
    "\n",
    "        # Compute means\n",
    "        mean_accuracy  = accuracy_scores.mean()\n",
    "        mean_precision = precision_scores.mean()\n",
    "        mean_recall    = recall_scores.mean()\n",
    "        mean_f1        = f1_scores.mean()\n",
    "\n",
    "        # Log parameters + metrics to MLflow\n",
    "        mlflow.log_param(\"Model\", name)\n",
    "        if hasattr(model, \"get_params\"):\n",
    "            mlflow.log_params(model.get_params())\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            \"CV_Accuracy\": mean_accuracy,\n",
    "            \"CV_Precision\": mean_precision,\n",
    "            \"CV_Recall\": mean_recall,\n",
    "            \"CV_F1\": mean_f1\n",
    "        })\n",
    "\n",
    "        # Store results\n",
    "        cv_results[name] = {\n",
    "            \"Accuracy\": mean_accuracy,\n",
    "            \"Precision\": mean_precision,\n",
    "            \"Recall\": mean_recall,\n",
    "            \"F1\": mean_f1\n",
    "        }\n",
    "\n",
    "        print(f\"{name}: Accuracy={mean_accuracy:.4f}, Precision={mean_precision:.4f}, Recall={mean_recall:.4f}, F1={mean_f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05ae70e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Best model from CV: Random Forest\n",
      "                     Accuracy  Precision    Recall        F1\n",
      "Logistic Regression  0.848877   0.856703  0.848877  0.850727\n",
      "Decision Tree        0.905712   0.906324  0.905956  0.905984\n",
      "K-Nearest Neighbors  0.876091   0.892901  0.876091  0.877604\n",
      "Random Forest        0.953366   0.954761  0.953366  0.953562\n",
      "XGBoost Classifier   0.945969   0.946805  0.945969  0.946059\n"
     ]
    }
   ],
   "source": [
    "# Compare models and select best one\n",
    "results_df = pd.DataFrame(cv_results).T\n",
    "best_model_name = results_df[\"Accuracy\"].idxmax()  # select by highest CV Accuracy\n",
    "best_model = models[best_model_name]\n",
    "print(f\"\\n‚úÖ Best model from CV: {best_model_name}\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a651a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = \"Random Forest\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afd59183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using best model: Random Forest\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"XGBoost Classifier\": XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "best_model = models[best_model_name]\n",
    "print(f\"‚úÖ Using best model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cabb7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    \"Random Forest\": {\n",
    "        'classifier__n_estimators': [100, 200, 300],\n",
    "        'classifier__max_depth': [5, 10, 15, None],\n",
    "        'classifier__min_samples_split': [2, 5, 10],\n",
    "        'classifier__min_samples_leaf': [1, 2, 4],\n",
    "        'classifier__max_features': ['sqrt', 'log2', None],\n",
    "        'classifier__bootstrap': [True, False]\n",
    "    },\n",
    "    \"XGBoost Classifier\": {\n",
    "        \"classifier__n_estimators\": [200, 300, 500],\n",
    "        \"classifier__max_depth\": [4, 6, 8],\n",
    "        \"classifier__learning_rate\": [0.01, 0.05, 0.1],\n",
    "        \"classifier__min_child_weight\": [1, 2],\n",
    "        \"classifier__gamma\": [0, 0.1],\n",
    "    },\n",
    "    \"Logistic Regression\": {\n",
    "        'classifier__C': [0.01, 0.1, 1, 10],\n",
    "        'classifier__penalty': ['l2'],\n",
    "        'classifier__solver': ['lbfgs']\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        'classifier__max_depth': [None, 5, 10, 15],\n",
    "        'classifier__min_samples_split': [2, 5, 10],\n",
    "        'classifier__min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        'classifier__n_neighbors': [3, 5, 7, 9],\n",
    "        'classifier__weights': ['uniform', 'distance'],\n",
    "        'classifier__p': [1, 2]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Select parameter grid for the best model\n",
    "param_grid = param_grids.get(best_model_name, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9002606a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "#  Hyperparameter tuning\n",
    "if param_grid:\n",
    "    pipeline = Pipeline([\n",
    "        ('feature_engineering', FeatureEngineer()),\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('feature_selector', feature_selector),\n",
    "        ('classifier', best_model)\n",
    "    ])\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"{best_model_name}_Tuning\"):\n",
    "        search = RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            param_distributions=param_grid,\n",
    "            n_iter=10,\n",
    "            cv=3,\n",
    "            scoring='accuracy',\n",
    "            verbose=1,\n",
    "            n_jobs=1,\n",
    "            random_state=42\n",
    "        )\n",
    "        search.fit(X_train, y_train)\n",
    "\n",
    "        best_estimator = search.best_estimator_\n",
    "        best_params = search.best_params_\n",
    "        best_score = search.best_score_\n",
    "\n",
    "        # Log params and CV score\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_metric(\"Best_CV_Accuracy\", best_score)\n",
    "\n",
    "        # Evaluate on test set\n",
    "        y_pred = best_estimator.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            \"Test_Accuracy\": accuracy,\n",
    "            \"Test_Precision\": precision,\n",
    "            \"Test_Recall\": recall,\n",
    "            \"Test_F1\": f1\n",
    "        })\n",
    "\n",
    "        # Save tuned model and log\n",
    "        model_filename = f\"{best_model_name}_best_pipeline.pkl\"\n",
    "        joblib.dump(best_estimator, model_filename)\n",
    "        mlflow.log_artifact(model_filename, artifact_path=\"models\")\n",
    "\n",
    "        print(f\" Best parameters: {best_params}\")\n",
    "        print(f\"Test Accuracy: {accuracy:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd9b3df",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed3db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# ---- Confusion Matrix ----\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix.png\", dpi=300)\n",
    "mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "plt.show()\n",
    "\n",
    "# ---- ROC Curve ----\n",
    "y_prob = best_estimator.predict_proba(X_test)\n",
    "n_classes = len(le.classes_)\n",
    "y_bin = label_binarize(y_test, classes=range(n_classes))\n",
    "\n",
    "fpr, tpr, roc_auc = {}, {}, {}\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_prob[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "for i, color in zip(range(n_classes), sns.color_palette(\"Set2\", n_classes)):\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, color=color,\n",
    "             label=f\"{le.classes_[i]} (AUC={roc_auc[i]:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curves\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(fontsize=9, loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"roc_curve.png\", dpi=300)\n",
    "mlflow.log_artifact(\"roc_curve.png\")\n",
    "plt.show()\n",
    "\n",
    "# ---- Log AUC metrics ----\n",
    "for i in range(n_classes):\n",
    "    mlflow.log_metric(f\"AUC_{le.classes_[i]}\", roc_auc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68977cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c269bdf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
